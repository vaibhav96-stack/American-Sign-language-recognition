{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "459869ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, InputLayer, BatchNormalization, Dropout\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcc3f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(r\"C:\\work\\ML\\Ml report\\MLReport (3)\\Finalmodel (1).h5\")#Model path "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdb6ed0",
   "metadata": {},
   "source": [
    "y_test=[]\n",
    "predictions=[]\n",
    "for i in range(26):\n",
    "    y_test.append(chr(i+65))\n",
    "\n",
    "dir_path= r'C:\\work\\ML\\Dataset\\Test'\n",
    "for i in os.listdir(dir_path):\n",
    "    img=image.load_img(dir_path+'//'+i,target_size=(64,64))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    X=image.img_to_array(img)\n",
    "    X=np.expand_dims(X,axis=0)\n",
    "    images=np.vstack([X])#vstack() function is used to stack the sequence of input arrays vertically to make a single array.\n",
    "    #print(images.shape)\n",
    "    value=model.predict(images)\n",
    "    \n",
    "    for val in range(0,len(value[0])):\n",
    "        if(value[0][val]==1):\n",
    "            \n",
    "            if val<26:\n",
    "                predictions.append(chr(val+65))\n",
    "                print(chr(val+65))\n",
    "          \n",
    "            break\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43de5f96",
   "metadata": {},
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb5df50",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(confusion_matrix(y_test,predictions))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2e8eb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = None\n",
    "accumulated_weight = 0.5\n",
    "\n",
    "ROI_top = 100\n",
    "ROI_bottom = 300\n",
    "ROI_right = 150\n",
    "ROI_left = 350\n",
    "def cal_accum_avg(frame, accumulated_weight):\n",
    "    global background\n",
    "    \n",
    "    if background is None:\n",
    "        background = frame.copy().astype(\"float\")\n",
    "        return None\n",
    "    cv2.accumulateWeighted(frame, background, accumulated_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9668393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_hand(frame, threshold=25):\n",
    "    global background\n",
    "    \n",
    "    diff = cv2.absdiff(background.astype(\"uint8\"), frame)\n",
    "    _ , thresholded = cv2.threshold(diff, threshold,255,cv2.THRESH_BINARY)\n",
    "    # Grab the external contours for the image\n",
    "    contours, hierarchy = cv2.findContours(thresholded.copy(),cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        \n",
    "        hand_segment_max_cont = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        return (thresholded, hand_segment_max_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d02e6810",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "num_frames =0\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    # ROI from the frame\n",
    "    roi = frame[ROI_top:ROI_bottom, ROI_right:ROI_left]\n",
    "\n",
    "    gray_frame = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (9, 9), 0)\n",
    "    #In image processing, a Gaussian blur is the result of blurring an image by a Gaussian function.\n",
    "\n",
    "\n",
    "    if num_frames < 70:\n",
    "        \n",
    "        cal_accum_avg(gray_frame, accumulated_weight)\n",
    "        \n",
    "        cv2.putText(frame_copy, \"FETCHING BACKGROUND...PLEASE WAIT\",\n",
    "  (80, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "    \n",
    "    else: \n",
    "        # segmenting the hand region\n",
    "        hand = segment_hand(gray_frame)\n",
    "        \n",
    "        # Checking if we are able to detect the hand...\n",
    "        if hand is not None:\n",
    "            \n",
    "            thresholded, hand_segment = hand\n",
    "\n",
    "            # Drawing contours around hand segment\n",
    "            cv2.drawContours(frame_copy, [hand_segment + (ROI_right,\n",
    "      ROI_top)], -1, (255, 0, 0),1)\n",
    "            \n",
    "            \n",
    "            cv2.imshow(\"Thesholded Hand Image\", thresholded)\n",
    "            thresholded = cv2.resize(thresholded, (64, 64))\n",
    "            thresholded = cv2.cvtColor(thresholded,cv2.COLOR_GRAY2RGB)\n",
    "            thresholded = np.reshape(thresholded,(1,thresholded.shape[0],thresholded.shape[1],3))\n",
    "            \n",
    "            #thresholded = cv2.cvtColor(thresholded, cv2.COLOR_RGB2GRAY)\n",
    "           #print(thresholded.shape)\n",
    "            #cv2.imshow(\"Thesholded Hand Image\", thresholded[:3])\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            pred = model.predict(thresholded)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #Added manually down one\n",
    "            \n",
    "            \n",
    "            letter=\"\"\n",
    "            for val in range(0,len(pred[0])):\n",
    "                if(pred[0][val]==1):\n",
    "            \n",
    "                    if val<26:\n",
    "                        letter=chr(val+65)\n",
    "                    else:\n",
    "                        if val==26:\n",
    "                            letter=\"EMPTY\"\n",
    "                        elif val==27:\n",
    "                            letter=\"SPACE\"\n",
    "                        else:\n",
    "                            letter=\"Model was not able to predict\"\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #cv2.putText(frame_copy, word_dict[np.argmax(pred)],(170, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.putText(frame_copy, letter,(170, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            \n",
    "    # Draw ROI on frame_copy\n",
    "    cv2.rectangle(frame_copy, (ROI_left, ROI_top), (ROI_right,\n",
    "    ROI_bottom), (255,128,0), 3)\n",
    "\n",
    "    # incrementing the number of frames for tracking\n",
    "    num_frames += 1\n",
    "\n",
    "    # Display the frame with segmented hand\n",
    "    cv2.putText(frame_copy, \"Word _ _ _\",(10, 20), cv2.FONT_ITALIC, 0.5, (51,255,51), 1)\n",
    "    cv2.imshow(\"Sign Detection\", frame_copy)\n",
    "\n",
    "\n",
    "    # Close windows with Esc\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "# Release the camera and destroy all the windows\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee77924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864889d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
